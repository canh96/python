{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_iris()['data']\n",
    "y = load_iris()['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x) :\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    c = np.max(x,axis=1).reshape(-1,1)\n",
    "    x = x-c\n",
    "    return np.exp(x)/np.sum(np.exp(x),axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_crossentropy(t,y):\n",
    "    return np.mean(-t*np.log(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one(x):\n",
    "    result = np.zeros((x.size,np.unique(x).size))\n",
    "    for idx1,idx2 in enumerate(x):\n",
    "        result[idx1,idx2] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = make_one(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1:]\n",
    "output_shape = y.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(4,50)\n",
    "b1 = np.zeros(50)\n",
    "W2 = np.random.randn(50,3)\n",
    "b2 = np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    W1 = np.random.randn(4,50)\n",
    "    b1 = np.zeros(50)\n",
    "    W2 = np.random.randn(50,3)\n",
    "    b2 = np.zeros(3)\n",
    "    layer1 = np.dot(x,W1) + b1\n",
    "    z1 = sigmoid(layer1)\n",
    "    layer2 = np.dot(z1,W2) + b2\n",
    "    out = softmax(layer2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f,x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh = f(x)\n",
    "        x[idx] = tmp_val - h\n",
    "        fx = f(x)\n",
    "        grad[idx] = (fxh-fx)/(2*h)\n",
    "        it.iternext()\n",
    "        x[idx] = tmp_val\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x : x[0]**2 + x[1]**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.        , 27.00000001])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(f,np.array([2.,3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_gradient(W_loss,W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x,t):\n",
    "    y = predict(x)\n",
    "    W_loss = lambda W: categorical_crossentropy(y,t)\n",
    "    dW1 = numerical_gradient(W_loss,W1)\n",
    "    db1 = numerical_gradient(W_loss,b1)\n",
    "    dW2 = numerical_gradient(W_loss,W2)\n",
    "    db2 = numerical_gradient(W_loss,b2)\n",
    "    W1 -= dW1*lr\n",
    "    b1 -= db1*lr\n",
    "    W2 -= dW2*lr\n",
    "    b2 -= db2*lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = np.dot(X,W1) + b1\n",
    "z1 = sigmoid(layer1)\n",
    "layer2 = np.dot(z1,W2) + b2\n",
    "out = softmax(layer2)\n",
    "lr = 1e-4\n",
    "W_loss = lambda W: categorical_crossentropy(y,out)\n",
    "dW1 = numerical_gradient(W_loss,W1)\n",
    "db1 = numerical_gradient(W_loss,b1)\n",
    "dW2 = numerical_gradient(W_loss,W2)\n",
    "db2 = numerical_gradient(W_loss,b2)\n",
    "W1 -= dW1*lr\n",
    "b1 -= db1*lr\n",
    "W2 -= dW2*lr\n",
    "b2 -= db2*lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5277144766684667"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_crossentropy(y,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5277144766684667"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_crossentropy(y,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7951979850172142"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = predict(X)\n",
    "categorical_crossentropy(y,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {}\n",
    "a['w1'] = a\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (645767825.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [148]\u001b[1;36m\u001b[0m\n\u001b[1;33m    def prob(x) :\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def prob(x) :\n",
    "    return x+0.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layer = {}\n",
    "        \n",
    "    def add(self, x1, x2, activation) :\n",
    "        activation_dict = {\n",
    "            'sigmoid' : sigmoid,\n",
    "            'relu' : relu,\n",
    "            'softmax' : softmax,\n",
    "            'prob' : prob\n",
    "        }\n",
    "        w = 'W'+str((int(len(self.layer)/3) + 1))\n",
    "        b = 'b'+str((int(len(self.layer)/3) + 1))\n",
    "        a = 'activation'+str((int(len(self.layer)/3) + 1))\n",
    "        \n",
    "        self.layer[w] = np.random.randn(x1,x2)\n",
    "        self.layer[b] = np.zeros(x2)\n",
    "        self.layer[a] = activation_dict[activation]\n",
    "        \n",
    "    def predict(self,x):\n",
    "        length = int(len(self.layer)/3)+1\n",
    "        y = x.copy()\n",
    "        for i in range(1, length):\n",
    "            w = 'W'+ str(i)\n",
    "            b = 'b'+ str(i)\n",
    "            a = 'activation'+str(i)\n",
    "            y = np.dot(y,self.layer[w]) + self.layer[b]\n",
    "            y = self.layer[a](y)\n",
    "        return y\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        err = categorical_crossentropy(t,y) \n",
    "        self.err = err\n",
    "        return self.err\n",
    "    \n",
    "    def accuracy(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y,axis=1)\n",
    "        t = np.argmax(t,axis=1)\n",
    "        self.acc = np.sum(y==t)/t.size\n",
    "        return self.acc\n",
    "    \n",
    "    def gradient(self,x,t):\n",
    "        #self.loss(x,t)\n",
    "        lr = 1e-4\n",
    "        W_loss = lambda W : self.loss(x,t)\n",
    "        length = int(len(self.layer)/3) + 1\n",
    "        for i in range(1,length) :\n",
    "            w = 'W' +str(i)\n",
    "            b = 'b' +str(i)\n",
    "            dW = numerical_gradient(W_loss,self.layer[w])\n",
    "            db = numerical_gradient(W_loss,self.layer[b])\n",
    "            self.layer[w] -= dW*lr\n",
    "            self.layer[b] -= db*lr\n",
    "        \n",
    "        \n",
    "    def fit(self,x,t,epochs) :\n",
    "        history = {}\n",
    "        accuracy = []\n",
    "        loss = []\n",
    "        for epoch in range(epochs) :\n",
    "            self.gradient(x,t)\n",
    "            loss.append[self.err]\n",
    "            accuracy.append(self.accuracy(x,t))\n",
    "            if epoch % 100 == 0:\n",
    "                print(f'loss : {self.err} === accuracy : {self.accuracy(x,t)}')\n",
    "                history['accuarcy'] = accuracy\n",
    "                history['loss'] = loss\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Network(0.5)\n",
    "model2 = Network(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model1.add(4,10,'relu')\n",
    "model1.add(10,3,'softmax')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model2.add(4,10,'relu')\n",
    "model2.add(10,3,'softmax')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.layer['W1'] = model1.layer['W1'] * 2.\n",
    "model2.layer['W2'] = model1.layer['W2'] * 2.\n",
    "model2.layer['W3'] = model1.layer['W3'] * 2.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.dot(X,np.random.randn(4,3))\n",
    "np.sum(prob(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(X,y,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.90793929,  1.30757094,  0.65659901, -0.33709326, -0.0430854 ,\n",
       "         -0.20843107, -0.13677681,  1.1185398 ,  0.74909805,  1.07810955,\n",
       "         -0.10908887, -0.94382716,  0.89599918,  0.71247817,  1.15404231,\n",
       "          0.16204402,  0.57034186,  0.57516782,  1.46684478, -0.77667778,\n",
       "         -1.30520251,  1.43782806,  0.18068703,  1.60041617,  0.3093977 ,\n",
       "         -0.2955283 ,  1.31436218,  0.31597576,  0.92683732, -0.90515725,\n",
       "         -0.77520425, -1.25073576, -0.0937023 ,  1.25052883, -0.20730657,\n",
       "         -0.73741297, -0.93195463, -0.30804302,  1.36681048, -0.30619679,\n",
       "         -0.22493087, -1.15342662,  1.37790834, -0.12066998,  0.82858632,\n",
       "         -0.47846432, -0.18548743, -0.43736344,  0.28862536,  0.37621815],\n",
       "        [ 1.22357939,  0.30522077, -2.04485586,  0.09695515, -1.52973397,\n",
       "         -0.23254839,  0.45483865,  0.58127967, -0.10122169, -0.45135461,\n",
       "          0.97185712, -0.06142887, -0.54275956, -1.63352525,  0.48514671,\n",
       "          0.23506298, -0.16080608, -0.42949003, -0.82349588, -0.37536443,\n",
       "          1.08191415, -0.68148427, -1.40577685, -0.7553483 , -0.72690395,\n",
       "          0.6443791 , -0.36555055, -1.59365193, -0.62600687, -0.06351614,\n",
       "         -0.71371555,  0.40600743,  0.53293899,  1.55358301, -0.44818063,\n",
       "         -0.00470017,  0.37135872,  1.75180389,  0.7795079 , -1.91589834,\n",
       "          1.38937775, -0.25888836, -0.59461834,  0.62297411, -0.65229926,\n",
       "          0.4316478 ,  1.37226448,  0.07739979, -0.20361912, -0.24379785],\n",
       "        [-1.15617965, -1.37894578, -0.73930334, -0.51544626, -0.60817463,\n",
       "          0.14226542,  0.1190259 , -0.69908572, -0.94506258,  1.74021253,\n",
       "         -0.70755344,  0.86850248, -0.36759506, -0.51022451,  1.00091   ,\n",
       "          1.11340424, -0.91887508, -0.47615175, -0.2999993 ,  0.62655415,\n",
       "         -0.25375801, -0.08016091, -0.16275934,  0.85296617,  1.00041234,\n",
       "         -0.7395358 , -0.82836519,  1.29921355,  1.70591957,  1.05023539,\n",
       "          0.30870189, -0.35182188,  0.83589314,  0.7893163 ,  0.12977679,\n",
       "         -0.23313765,  0.15427727, -1.08208108,  1.97416289,  0.1223218 ,\n",
       "         -1.83963105,  0.43295984, -2.02081124, -0.30146714,  0.64210301,\n",
       "          1.25436358,  1.01277995, -0.66031374,  1.24946756,  0.02639372],\n",
       "        [-0.96660717, -0.34727388, -0.60006212,  0.50787794, -0.24915116,\n",
       "          0.26002291, -1.1437446 , -0.86277269, -1.12869572,  0.07193078,\n",
       "         -1.08150449, -1.40412278, -0.65373625,  0.0145993 ,  0.48900497,\n",
       "         -0.81686009, -0.47906048, -0.07695372, -1.89364354,  2.1781318 ,\n",
       "          0.14376803, -0.09564969, -0.97474943, -0.59872801,  1.67032066,\n",
       "          0.07892582,  0.44778132,  0.13753018, -0.76974132, -0.63176058,\n",
       "          0.21853601,  0.48345361,  0.90747097,  0.16637035,  0.4106187 ,\n",
       "          1.6913557 ,  1.47306526, -0.78163086,  0.71235211, -0.51937502,\n",
       "         -0.35478798, -0.07252837, -0.50286765, -1.6181897 ,  2.3269392 ,\n",
       "          1.01449564, -0.98138233, -0.19215151, -0.16891558, -1.87333202]]),\n",
       " 'b1': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'activation1': <function __main__.softmax(x)>,\n",
       " 'W2': array([[-0.09553784,  1.78584789,  0.42414254,  0.58841043,  0.28287653,\n",
       "         -1.59327451, -1.60594471, -2.28572696, -1.89302338,  1.48825078,\n",
       "          0.55151012, -0.94369879,  0.08089467, -1.22302538,  0.95610001,\n",
       "         -1.02083543,  1.63057124,  1.85936355,  1.10631073,  0.44366802,\n",
       "         -0.15111119, -1.03989715, -0.14199937, -1.14377734, -1.57043474,\n",
       "         -1.68442487,  0.12606136, -1.89529149, -0.34117408,  0.64760159,\n",
       "          0.40920607, -1.70848569,  1.97090057, -1.29793437, -1.77516363,\n",
       "         -0.69997839, -0.53909411, -2.17233208,  0.65057635,  1.01560517,\n",
       "         -0.45017673, -0.57338348,  0.97147305,  0.19396796,  0.93038248,\n",
       "          0.90108753,  0.5121264 ,  1.55189484, -0.01983358,  0.80159432],\n",
       "        [-0.30060405,  0.14864622,  0.22902924, -0.60390814, -1.02276998,\n",
       "          0.98438553,  0.30878043,  0.14450154, -0.62156554,  0.85264133,\n",
       "          0.14237011,  0.87930257, -1.61040811, -1.1188318 , -0.72564945,\n",
       "          2.10694255,  0.84305511, -0.07099442,  1.15180234, -0.7598841 ,\n",
       "          1.50554518,  0.97020426,  2.46449075,  0.64774756, -0.72789697,\n",
       "         -0.58284452, -0.00531245,  0.43315278,  0.06256307, -1.32553922,\n",
       "         -0.43727588, -1.77717144, -0.48676552,  0.76757682,  0.0862581 ,\n",
       "         -1.55114462, -1.10963399,  0.05836723, -0.0855692 ,  1.45500459,\n",
       "          0.78335489,  0.48157394,  1.01188419, -0.99989904,  0.44042546,\n",
       "          0.03255873,  0.1646835 ,  1.09872092,  0.01181763, -0.037588  ],\n",
       "        [ 0.04248643,  0.14931732, -0.87883343, -0.19467703, -0.12912825,\n",
       "          0.06792521,  0.14483068, -0.31969132,  0.9211838 , -0.58172426,\n",
       "          1.16472902, -0.25803018,  0.11994558, -2.26213154,  0.07477666,\n",
       "          0.03365549,  0.93776598,  0.28190069, -0.76137356, -1.70984534,\n",
       "         -1.44700192, -0.9388596 , -0.95888352,  0.68317931,  0.6055867 ,\n",
       "         -0.18805749,  0.43587275,  0.51410962, -0.43375161, -1.65094736,\n",
       "          0.83233634, -0.55491188, -1.48858247,  1.14734329,  0.40080413,\n",
       "          1.46052296,  0.33387579,  1.39931353, -0.8301994 ,  0.91709345,\n",
       "          1.21551663, -0.61591522, -1.07102545, -1.45359176, -1.04381726,\n",
       "          1.18764736, -0.44994502,  0.45342387, -1.02992462,  0.50174594],\n",
       "        [-0.74418967,  0.1114648 , -1.00033868,  1.12548556,  1.41788547,\n",
       "          0.46216817,  0.45849374, -0.48848331,  0.37974448, -1.51550446,\n",
       "         -1.801106  ,  0.79549927, -0.45987021, -1.04708154, -0.30039372,\n",
       "         -1.69165535,  1.121398  ,  1.12180258, -0.72944235, -2.05279604,\n",
       "         -0.62266462, -0.32136453, -0.47753989, -1.27043399,  0.3585847 ,\n",
       "          0.04213681,  0.44912287,  0.9873416 , -0.89631369, -0.94244492,\n",
       "          0.27314841, -0.12134256, -1.42555274,  2.55332341, -0.62883374,\n",
       "          0.07866814, -1.89381885,  0.02842657,  1.02115565,  2.07549222,\n",
       "          0.19392174,  1.02763583,  0.73454494, -1.03147273,  0.22117485,\n",
       "         -1.26894423, -1.05298161,  0.15952588,  1.07253407,  0.69481782]]),\n",
       " 'b2': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'activation2': <function __main__.sigmoid(x)>}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\admin\\STUDY\\딥러닝\\1day\\Untitled9.ipynb 셀 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mlayer[\u001b[39m'\u001b[39;49m\u001b[39mactivation1\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m1\u001b[39;49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model.layer['activation1']\n",
    "# for _,v in model.layer.items():\n",
    "#     print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\admin\\STUDY\\딥러닝\\1day\\Untitled9.ipynb 셀 25\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X,y)\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'epochs'"
     ]
    }
   ],
   "source": [
    "# model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.4, 2.9, 1.4, 0.2]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[[8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(X[[8]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 2.787337548633541 === accuracy : 0.34\n",
      "loss : 1.4966590826928798 === accuracy : 0.36666666666666664\n",
      "loss : 1.3211960116220043 === accuracy : 0.38\n",
      "loss : 1.2403061794077743 === accuracy : 0.36666666666666664\n",
      "loss : 1.1702030177298566 === accuracy : 0.37333333333333335\n",
      "loss : 1.1014161305804828 === accuracy : 0.37333333333333335\n",
      "loss : 1.0329860479844193 === accuracy : 0.38\n",
      "loss : 0.9651221643373933 === accuracy : 0.37333333333333335\n",
      "loss : 0.8980705735089805 === accuracy : 0.36666666666666664\n",
      "loss : 0.8328974613504448 === accuracy : 0.36666666666666664\n",
      "loss : 0.7694463656309752 === accuracy : 0.37333333333333335\n",
      "loss : 0.707701393555339 === accuracy : 0.38\n",
      "loss : 0.6480497571085804 === accuracy : 0.38666666666666666\n",
      "loss : 0.5910278453350861 === accuracy : 0.38666666666666666\n",
      "loss : 0.5374131364976144 === accuracy : 0.38666666666666666\n",
      "loss : 0.4874790037972219 === accuracy : 0.3933333333333333\n",
      "loss : 0.44137288662885876 === accuracy : 0.4\n",
      "loss : 0.399560661645761 === accuracy : 0.44666666666666666\n",
      "loss : 0.3621121204228521 === accuracy : 0.48\n",
      "loss : 0.3288419824901217 === accuracy : 0.5133333333333333\n",
      "loss : 0.29963140671900373 === accuracy : 0.56\n",
      "loss : 0.2741554056627899 === accuracy : 0.5933333333333334\n",
      "loss : 0.2519680658560667 === accuracy : 0.6266666666666667\n",
      "loss : 0.23275333212307417 === accuracy : 0.6533333333333333\n",
      "loss : 0.21612066864433604 === accuracy : 0.6933333333333334\n",
      "loss : 0.2016765691974617 === accuracy : 0.7266666666666667\n",
      "loss : 0.18912756295589217 === accuracy : 0.7733333333333333\n",
      "loss : 0.17817708446573646 === accuracy : 0.78\n",
      "loss : 0.1686048093370109 === accuracy : 0.7933333333333333\n",
      "loss : 0.16020807474495216 === accuracy : 0.8\n",
      "loss : 0.15278949743549533 === accuracy : 0.8066666666666666\n",
      "loss : 0.14621352219841183 === accuracy : 0.8133333333333334\n",
      "loss : 0.14036670102183665 === accuracy : 0.8133333333333334\n",
      "loss : 0.1351468866124604 === accuracy : 0.8333333333333334\n",
      "loss : 0.13046474337145741 === accuracy : 0.8466666666666667\n",
      "loss : 0.1262541394481377 === accuracy : 0.8466666666666667\n",
      "loss : 0.122449952491079 === accuracy : 0.8466666666666667\n",
      "loss : 0.11900507280071572 === accuracy : 0.8466666666666667\n",
      "loss : 0.11588660047767939 === accuracy : 0.8666666666666667\n",
      "loss : 0.11303732943893906 === accuracy : 0.8733333333333333\n",
      "loss : 0.11042622458483811 === accuracy : 0.88\n",
      "loss : 0.10802551760390842 === accuracy : 0.8933333333333333\n",
      "loss : 0.10581357534528112 === accuracy : 0.9\n",
      "loss : 0.10377228441028828 === accuracy : 0.9\n",
      "loss : 0.1018800365528124 === accuracy : 0.9\n",
      "loss : 0.10011071274448527 === accuracy : 0.9\n",
      "loss : 0.09845915905973845 === accuracy : 0.9\n",
      "loss : 0.09689917449617952 === accuracy : 0.9\n",
      "loss : 0.09543278037577642 === accuracy : 0.9\n",
      "loss : 0.09405941945204069 === accuracy : 0.9133333333333333\n",
      "loss : 0.09277416738524437 === accuracy : 0.92\n",
      "loss : 0.09156250691329998 === accuracy : 0.9266666666666666\n",
      "loss : 0.09041977322846388 === accuracy : 0.9266666666666666\n",
      "loss : 0.08928373654136308 === accuracy : 0.9266666666666666\n",
      "loss : 0.08818518146456275 === accuracy : 0.9266666666666666\n",
      "loss : 0.08712657388035094 === accuracy : 0.9333333333333333\n",
      "loss : 0.08612057104939186 === accuracy : 0.9333333333333333\n",
      "loss : 0.0851768710369401 === accuracy : 0.9333333333333333\n",
      "loss : 0.08428318980971647 === accuracy : 0.9333333333333333\n",
      "loss : 0.08343096515940826 === accuracy : 0.9333333333333333\n",
      "loss : 0.08262045891124034 === accuracy : 0.9333333333333333\n",
      "loss : 0.0818445985811147 === accuracy : 0.9333333333333333\n",
      "loss : 0.0811008886775996 === accuracy : 0.9333333333333333\n",
      "loss : 0.08038711738449725 === accuracy : 0.9333333333333333\n",
      "loss : 0.07971121513373926 === accuracy : 0.9333333333333333\n",
      "loss : 0.07906728678396456 === accuracy : 0.9333333333333333\n",
      "loss : 0.07845001146715201 === accuracy : 0.9333333333333333\n",
      "loss : 0.07785455654615472 === accuracy : 0.9333333333333333\n",
      "loss : 0.07725880977855659 === accuracy : 0.9333333333333333\n",
      "loss : 0.0766828573925562 === accuracy : 0.9266666666666666\n",
      "loss : 0.07612663212929784 === accuracy : 0.9266666666666666\n",
      "loss : 0.07559643898486958 === accuracy : 0.9266666666666666\n",
      "loss : 0.07509240901032627 === accuracy : 0.9266666666666666\n",
      "loss : 0.07460342390200946 === accuracy : 0.9266666666666666\n",
      "loss : 0.07412696699678199 === accuracy : 0.9266666666666666\n",
      "loss : 0.07366499987493347 === accuracy : 0.9266666666666666\n",
      "loss : 0.07321679677286083 === accuracy : 0.9266666666666666\n",
      "loss : 0.07278119934978619 === accuracy : 0.9266666666666666\n",
      "loss : 0.07235788015314121 === accuracy : 0.9266666666666666\n",
      "loss : 0.07194487511796643 === accuracy : 0.9266666666666666\n",
      "loss : 0.071536471212323 === accuracy : 0.9266666666666666\n",
      "loss : 0.07113560976236721 === accuracy : 0.9266666666666666\n",
      "loss : 0.07074270533942405 === accuracy : 0.9266666666666666\n",
      "loss : 0.07035754351434415 === accuracy : 0.9266666666666666\n",
      "loss : 0.06997974685491683 === accuracy : 0.9266666666666666\n",
      "loss : 0.06961803107076132 === accuracy : 0.9266666666666666\n",
      "loss : 0.06928084488757578 === accuracy : 0.9266666666666666\n",
      "loss : 0.06895221730655698 === accuracy : 0.9266666666666666\n",
      "loss : 0.06863119718279334 === accuracy : 0.9266666666666666\n",
      "loss : 0.06831758223654678 === accuracy : 0.9333333333333333\n",
      "loss : 0.0680110833549935 === accuracy : 0.9333333333333333\n",
      "loss : 0.0677113485322745 === accuracy : 0.9333333333333333\n",
      "loss : 0.06741812403567672 === accuracy : 0.9333333333333333\n",
      "loss : 0.0671311722150828 === accuracy : 0.9333333333333333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\admin\\STUDY\\딥러닝\\1day\\Untitled9.ipynb 셀 29\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs): \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model\u001b[39m.\u001b[39;49mgradient(X,y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss : \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39merr\u001b[39m}\u001b[39;00m\u001b[39m === accuracy : \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39maccuracy(X,y)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\admin\\STUDY\\딥러닝\\1day\\Untitled9.ipynb 셀 29\u001b[0m in \u001b[0;36mNetwork.gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m W_loss \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m W : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(x,t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m dW1 \u001b[39m=\u001b[39m numerical_gradient(W_loss,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW1)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m db1 \u001b[39m=\u001b[39m numerical_gradient(W_loss,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mb1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m dW2 \u001b[39m=\u001b[39m numerical_gradient(W_loss,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m db2 \u001b[39m=\u001b[39m numerical_gradient(W_loss,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb2)\n",
      "\u001b[1;32mc:\\Users\\admin\\STUDY\\딥러닝\\1day\\Untitled9.ipynb 셀 29\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m fxh \u001b[39m=\u001b[39m f(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m x[idx] \u001b[39m=\u001b[39m tmp_val \u001b[39m-\u001b[39m h\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m fx \u001b[39m=\u001b[39m f(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m grad[idx] \u001b[39m=\u001b[39m (fxh\u001b[39m-\u001b[39mfx)\u001b[39m/\u001b[39m(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mh)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m it\u001b[39m.\u001b[39miternext()\n",
      "\u001b[1;32mc:\\Users\\admin\\STUDY\\딥러닝\\1day\\Untitled9.ipynb 셀 29\u001b[0m in \u001b[0;36mNetwork.gradient.<locals>.<lambda>\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgradient\u001b[39m(\u001b[39mself\u001b[39m,x,t):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m#self.loss(x,t)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     lr \u001b[39m=\u001b[39m \u001b[39m1e-4\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     W_loss \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m W : \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(x,t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     dW1 \u001b[39m=\u001b[39m numerical_gradient(W_loss,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     db1 \u001b[39m=\u001b[39m numerical_gradient(W_loss,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb1)\n",
      "\u001b[1;32mc:\\Users\\admin\\STUDY\\딥러닝\\1day\\Untitled9.ipynb 셀 29\u001b[0m in \u001b[0;36mNetwork.loss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m,x,t):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     err \u001b[39m=\u001b[39m categorical_crossentropy(t,y) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merr \u001b[39m=\u001b[39m err\n",
      "\u001b[1;32mc:\\Users\\admin\\STUDY\\딥러닝\\1day\\Untitled9.ipynb 셀 29\u001b[0m in \u001b[0;36mNetwork.predict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(x,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW1) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m y \u001b[39m=\u001b[39m relu(y)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(y,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW2) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m y \u001b[39m=\u001b[39m softmax(y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "for epoch in range(epochs): \n",
    "    model.gradient(X,y)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'loss : {model.err} === accuracy : {model.accuracy(X,y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-205-459a19009c56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-203-bea8586293e8>\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mW_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mW\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mdW1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mdb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mdW2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-144-c4e16d176344>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mfxh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfxh\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mfx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miternext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-203-bea8586293e8>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m#self.loss(x,t)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mW_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mW\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mdW1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mdb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "model.gradient(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\admin\\STUDY\\딥러닝\\1day\\Untitled9.ipynb 셀 44\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m mnist\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/%EB%94%A5%EB%9F%AC%EB%8B%9D/1day/Untitled9.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense, Flatten\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from \n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Flatten\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "610a6f344c2137faf927ea819c63f6cee33a2c04455044b28099f39fe9722347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
